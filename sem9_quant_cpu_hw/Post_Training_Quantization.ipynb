{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip list | grep torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ypQKMC0QIjA",
        "outputId": "1b444b02-4f1b-40f5-9c5a-d08a7b890494"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch                                    2.8.0+cu126\n",
            "torchao                                  0.10.0\n",
            "torchaudio                               2.8.0+cu126\n",
            "torchdata                                0.11.0\n",
            "torchsummary                             1.5.1\n",
            "torchtune                                0.6.1\n",
            "torchvision                              0.23.0+cu126\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "NhEMHX1V4IwM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   https://pytorch.org/blog/quantization-in-practice/\n",
        "*   https://pytorch.org/docs/stable/quantization.html\n",
        "*   https://pytorch.org/docs/stable/quantization-support.html"
      ],
      "metadata": {
        "id": "RoMW3Ruptax1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mapping function and Quantization Parameters"
      ],
      "metadata": {
        "id": "gbqyoRrl7A0y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# r - float tensor, r' - int tensor\n",
        "# S [scaling factor] = (beta - alpha) / (beta_q - alpha_q)\n",
        "# Z [zero point] =  -(alpha / S - alpha_q)\n",
        "\n",
        "def quantize(float_tensor, scale, z):\n",
        "  # Q(r) = round(r/S + Z)\n",
        "  return torch.round(float_tensor / scale + z)\n",
        "\n",
        "def dequantize(int_tensor, scale, z):\n",
        "  # r' = (Q(r) - Z) * S\n",
        "  return (int_tensor - z) * scale"
      ],
      "metadata": {
        "id": "XbgzwD7M1KW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.ao.quantization.observer import MinMaxObserver, MovingAverageMinMaxObserver, HistogramObserver\n",
        "\n",
        "C, L = 3, 4\n",
        "normal = torch.distributions.normal.Normal(0,1)\n",
        "inputs = normal.sample((C, L))\n",
        "print(inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBAf6XZi1KXs",
        "outputId": "f16c2424-feb7-4948-e47a-35494fbca6aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.7192,  0.1141,  0.6485, -1.7600],\n",
            "        [-0.6397,  0.4609, -0.0305,  0.4960],\n",
            "        [ 0.8219,  1.0282,  0.6871, -1.8108]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "observers = [MinMaxObserver(), MovingAverageMinMaxObserver(), HistogramObserver()]\n",
        "for obs in observers:\n",
        "  obs(inputs)\n",
        "  print(obs.__class__.__name__, obs.calculate_qparams())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPanD_eQ4TZl",
        "outputId": "deeacd80-65f6-45ce-d5ef-8625b8522fac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MinMaxObserver (tensor([0.0111]), tensor([163], dtype=torch.int32))\n",
            "MovingAverageMinMaxObserver (tensor([0.0111]), tensor([163], dtype=torch.int32))\n",
            "HistogramObserver (tensor([0.0111]), tensor([163], dtype=torch.int32))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scale, z = observers[0].calculate_qparams()\n",
        "reconstruction_error = torch.abs(dequantize(quantize(inputs, scale, z), scale, z) - inputs)\n",
        "reconstruction_error"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZf3OgNQ49Aj",
        "outputId": "b55cf5f0-5755-4179-fd26-cd8816d9bd4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0044, 0.0027, 0.0027, 0.0009],\n",
              "        [0.0051, 0.0044, 0.0029, 0.0050],\n",
              "        [0.0020, 0.0040, 0.0032, 0.0040]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Affine and Symmetric Quantization Schemes"
      ],
      "metadata": {
        "id": "vb5qUkHP8sUE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def get_symmetric_range(x):\n",
        "  beta = torch.max(x.max(), x.min().abs())\n",
        "  return -beta.item(), beta.item()\n",
        "\n",
        "def get_affine_range(x):\n",
        "  return x.min().item(), x.max().item()\n",
        "\n",
        "def plot(plt, data, scheme):\n",
        "  boundaries = get_affine_range(data) if scheme == 'affine' else get_symmetric_range(data)\n",
        "  a, _, _ = plt.hist(data, density=True, bins=100)\n",
        "  ymin, ymax = np.quantile(a[a>0], [0.25, 0.95])\n",
        "  plt.vlines(x=boundaries, ls='--', colors='purple', ymin=ymin, ymax=ymax)"
      ],
      "metadata": {
        "id": "x8cv_y6f8tT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "act =  torch.distributions.pareto.Pareto(1, 10).sample((1, 1024))\n",
        "weights = torch.distributions.normal.Normal(0, 0.12).sample((3, 64, 7, 7)).flatten()\n",
        "\n",
        "fig, axs = plt.subplots(2,2)\n",
        "plot(axs[0, 0], act, 'affine')\n",
        "axs[0, 0].set_title(\"Activation, Affine-Quantized\")\n",
        "\n",
        "plot(axs[0, 1], act, 'symmetric')\n",
        "axs[0, 1].set_title(\"Activation, Symmetric-Quantized\")\n",
        "\n",
        "plot(axs[1, 0], weights, 'affine')\n",
        "axs[1, 0].set_title(\"Weights, Affine-Quantized\")\n",
        "\n",
        "plot(axs[1, 1], weights, 'symmetric')\n",
        "axs[1, 1].set_title(\"Weights, Symmetric-Quantized\")\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NTMv0kcB8128",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "outputId": "00f4b016-f8a0-42ce-9f84-6c2186988acc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for qscheme in [torch.per_tensor_affine, torch.per_tensor_symmetric]:\n",
        "  obs = MovingAverageMinMaxObserver(qscheme=qscheme)\n",
        "  obs(inputs)\n",
        "  print(f\"Qscheme: {qscheme} | {obs.calculate_qparams()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bej5FWvR-UDK",
        "outputId": "bcdc908e-5ac2-4d2c-c9a7-c7a93b4f1aae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Qscheme: torch.per_tensor_affine | (tensor([0.0111]), tensor([163], dtype=torch.int32))\n",
            "Qscheme: torch.per_tensor_symmetric | (tensor([0.0142]), tensor([128]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Per-Tensor and Per-Channel Quantization Schemes"
      ],
      "metadata": {
        "id": "wc4Zd5M99fTo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.ao.quantization.observer import MovingAveragePerChannelMinMaxObserver\n",
        "\n",
        "obs = MovingAveragePerChannelMinMaxObserver(ch_axis = 0)  # calculate qparams for all `C` channels separately\n",
        "obs(inputs)\n",
        "print(obs.calculate_qparams())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Dltyo4q9l-4",
        "outputId": "10a08eda-a0cf-41f4-f1b5-d392cd4c3428"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([0.0094, 0.0045, 0.0111]), tensor([186, 144, 163], dtype=torch.int32))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For weights quantization, symmetric-per-channel quantization provides better accuracies; per-tensor quantization performs poorly, possibly due to high variance in conv weights across channels from batchnorm folding.\n",
        "[https://arxiv.org/abs/2004.09602]"
      ],
      "metadata": {
        "id": "oOd8W97_AAMW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/pytorch/pytorch/blob/748d9d24940cd17938df963456c90fa1a13f3932/torch/ao/quantization/observer.py#L258"
      ],
      "metadata": {
        "id": "XvWTOGgv9gmI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Backend Engine"
      ],
      "metadata": {
        "id": "MiBMYYJMBC0A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "backend = 'fbgemm' #'fbgemm' if x86 else 'qnnpack' intel - oneDNN\n",
        "qconfig = torch.ao.quantization.get_default_qconfig(backend)\n",
        "torch.backends.quantized.engine = backend"
      ],
      "metadata": {
        "id": "9OgF7U86BDw7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GPUs - via TensorRT and cuDNN\n",
        "https://pytorch.org/docs/stable/quantization.html#note-for-native-cpu-backends"
      ],
      "metadata": {
        "id": "atxxYA28Bcvz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### QConfig"
      ],
      "metadata": {
        "id": "Jk-uxMCWBpRl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_qconfig = torch.ao.quantization.QConfig(\n",
        "  activation=MovingAverageMinMaxObserver.with_args(qscheme=torch.per_tensor_affine),\n",
        "  weight=MovingAveragePerChannelMinMaxObserver.with_args(qscheme=torch.qint8))\n",
        "\n",
        "my_qconfig"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3xygBpkBqKW",
        "outputId": "14dcad9c-e6f9-4c3d-ed18-6965290fc05c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, qscheme=torch.per_tensor_affine){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, qscheme=torch.qint8){})"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvsq4t68Kwj7",
        "outputId": "497c7aef-f6d4-464c-ed63-a9a24b63059a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.per_channel_affine"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Eager Mode v/s FX Graph Mode"
      ],
      "metadata": {
        "id": "8mh00mEaV4wy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*    Eager Mode Quantization is a beta feature. User needs to do fusion and specify where quantization and dequantization happens manually, also it only supports modules and not functionals.\n",
        "*    FX Graph Mode Quantization is a new automated quantization framework in PyTorch, and currently its a prototype feature. It improves upon Eager Mode Quantization by adding support for functionals and automating the quantization process, although people might need to refactor the model to make the model compatible with FX Graph Mode Quantization (symbolically traceable with torch.fx)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZLkEva02V_Co"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "FX Graph Mode automatically fuses eligible modules, inserts Quant/DeQuant stubs, calibrates the model and returns a quantized module - all in two method calls - but only for networks that are symbolic traceable. The examples below contain the calls using Eager Mode and FX Graph Mode for comparison.\n",
        "https://pytorch.org/docs/stable/fx.html#torch.fx.symbolic_trace"
      ],
      "metadata": {
        "id": "nWjnQot3Wzg-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def f(a, b):\n",
        "    if b == True:\n",
        "        return a\n",
        "    else:\n",
        "        return a * 2"
      ],
      "metadata": {
        "id": "el4bJKgIV6y7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f = torch.fx.symbolic_trace(f, concrete_args={'b': False})\n",
        "assert f(3, True) == 6"
      ],
      "metadata": {
        "id": "PkVCexZefVIX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "outputId": "c726d8dc-1a30-4987-d196-2755639d20f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "b has been specialized to have value False but got another value",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1040574657.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbolic_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcrete_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'b'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py\u001b[0m in \u001b[0;36mcall_wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    846\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcall_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrapped_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m         \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_wrapped\u001b[0m  \u001b[0;31m# type: ignore[method-assign]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m    422\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# noqa: B904\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m    409\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcls_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<eval_with_key>.4 from <eval_with_key>.3 from <eval_with_key>.2 from /tmp/ipython-input-2855332725.py:1 in f:4 in forward:4 in forward\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, a, b_1)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0meq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb_1\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mb_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0m_assert\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b has been specialized to have value False but got another value'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0meq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_assert\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mmul\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmul\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/__init__.py\u001b[0m in \u001b[0;36m_assert\u001b[0;34m(condition, message)\u001b[0m\n\u001b[1;32m   2172\u001b[0m             \u001b[0m_assert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcondition\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcondition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2173\u001b[0m         )\n\u001b[0;32m-> 2174\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mcondition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: b has been specialized to have value False but got another value"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://pytorch.org/docs/stable/fx.html"
      ],
      "metadata": {
        "id": "Temh_oTBfjE8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Post-Training Dynamic/Weight-only Quantization"
      ],
      "metadata": {
        "id": "lfxsmoBtXOgb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here the models weights are pre-quantized; the activations are quantized on-the-fly (dynamic) during inference. The simplest of all approaches, it has a one line API call in torch.quantization.quantize_dynamic. Currently only Linear and Recurrent (LSTM, GRU, RNN) layers are supported for dynamic quantization\n",
        "\n",
        "\n",
        "\n",
        "*   Can result in higher accuracies since the clipping range is exactly calibrated for each input\n",
        "*   Calibrating and quantizing the activations at each layer during runtime can add to the compute overhead\n",
        "\n"
      ],
      "metadata": {
        "id": "APgH-cqYdx6O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "\n",
        "# toy model\n",
        "m = nn.Sequential(\n",
        "  nn.Conv2d(2, 64, (8,)),\n",
        "  nn.ReLU(),\n",
        "  nn.Linear(16, 10),\n",
        "  nn.LSTM(10, 10))\n",
        "\n",
        "m.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CqIHv8efWt2l",
        "outputId": "2e8d79e3-ef19-4da1-eb7e-fc2eda357a0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Conv2d(2, 64, kernel_size=(8,), stride=(1, 1))\n",
              "  (1): ReLU()\n",
              "  (2): Linear(in_features=16, out_features=10, bias=True)\n",
              "  (3): LSTM(10, 10)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## EAGER MODE\n",
        "from torch.ao.quantization import quantize_dynamic\n",
        "\n",
        "model_quantized = quantize_dynamic(\n",
        "    model=m, qconfig_spec={nn.LSTM, nn.Linear}, dtype=torch.qint8, inplace=False\n",
        ")"
      ],
      "metadata": {
        "id": "2jhhTCrvXYv4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc99d28f-0639-4782-b741-86dfdb70138a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2181302342.py:4: DeprecationWarning: torch.ao.quantization is deprecated and will be removed in 2.10. \n",
            "For migrations of users: \n",
            "1. Eager mode quantization (torch.ao.quantization.quantize, torch.ao.quantization.quantize_dynamic), please migrate to use torchao eager mode quantize_ API instead \n",
            "2. FX graph mode quantization (torch.ao.quantization.quantize_fx.prepare_fx,torch.ao.quantization.quantize_fx.convert_fx, please migrate to use torchao pt2e quantization API instead (prepare_pt2e, convert_pt2e) \n",
            "3. pt2e quantization has been migrated to torchao (https://github.com/pytorch/ao/tree/main/torchao/quantization/pt2e) \n",
            "see https://github.com/pytorch/ao/issues/2259 for more details\n",
            "  model_quantized = quantize_dynamic(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## FX MODE\n",
        "from torch.ao.quantization import quantize_fx\n",
        "\n",
        "example_inputs = (torch.randn(1, 3, 224, 224),)\n",
        "qconfig_dict = {\"\": torch.ao.quantization.default_dynamic_qconfig}  # An empty key denotes the default applied to all modules\n",
        "model_prepared = quantize_fx.prepare_fx(m, qconfig_dict, example_inputs)\n",
        "model_quantized = quantize_fx.convert_fx(model_prepared)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PC5aJPPgXaO_",
        "outputId": "bad84414-ae8e-4cec-ef68-c453fd0254b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-15622409.py:6: DeprecationWarning: torch.ao.quantization is deprecated and will be removed in 2.10. \n",
            "For migrations of users: \n",
            "1. Eager mode quantization (torch.ao.quantization.quantize, torch.ao.quantization.quantize_dynamic), please migrate to use torchao eager mode quantize_ API instead \n",
            "2. FX graph mode quantization (torch.ao.quantization.quantize_fx.prepare_fx,torch.ao.quantization.quantize_fx.convert_fx, please migrate to use torchao pt2e quantization API instead (prepare_pt2e, convert_pt2e) \n",
            "3. pt2e quantization has been migrated to torchao (https://github.com/pytorch/ao/tree/main/torchao/quantization/pt2e) \n",
            "see https://github.com/pytorch/ao/issues/2259 for more details\n",
            "  model_prepared = quantize_fx.prepare_fx(m, qconfig_dict, example_inputs)\n",
            "/usr/local/lib/python3.12/dist-packages/torch/ao/quantization/quantize_fx.py:146: FutureWarning: Passing a QConfig dictionary to prepare is deprecated and will not be supported in a future version. Please pass in a QConfigMapping instead.\n",
            "  prepared = prepare(\n",
            "/tmp/ipython-input-15622409.py:7: DeprecationWarning: torch.ao.quantization is deprecated and will be removed in 2.10. \n",
            "For migrations of users: \n",
            "1. Eager mode quantization (torch.ao.quantization.quantize, torch.ao.quantization.quantize_dynamic), please migrate to use torchao eager mode quantize_ API instead \n",
            "2. FX graph mode quantization (torch.ao.quantization.quantize_fx.prepare_fx,torch.ao.quantization.quantize_fx.convert_fx, please migrate to use torchao pt2e quantization API instead (prepare_pt2e, convert_pt2e) \n",
            "3. pt2e quantization has been migrated to torchao (https://github.com/pytorch/ao/tree/main/torchao/quantization/pt2e) \n",
            "see https://github.com/pytorch/ao/issues/2259 for more details\n",
            "  model_quantized = quantize_fx.convert_fx(model_prepared)\n",
            "/usr/local/lib/python3.12/dist-packages/torch/ao/nn/quantized/reference/modules/rnn.py:461: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  torch.tensor(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/ao/nn/quantized/reference/modules/rnn.py:467: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  torch.tensor(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.ao.quantization.default_dynamic_qconfig"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lwvpek4HMxer",
        "outputId": "d3795509-45bc-4926-9757-2400ad784fc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.PlaceholderObserver'>, dtype=torch.quint8, quant_min=0, quant_max=255, is_dynamic=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Post-Training Static Quantization (PTQ)"
      ],
      "metadata": {
        "id": "a_Dd8gxLaNmy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PTQ also pre-quantizes model weights but instead of calibrating activations on-the-fly, the clipping range is pre-calibrated and fixed (static) using validation data. Activations stay in quantized precision between operations during inference. About 100 mini-batches of representative data are sufficient to calibrate the observers\n",
        "\n",
        "*   Static quantization has faster inference than dynamic quantization because it eliminates the float<->int conversion costs between layers\n",
        "*   Static quantized models may need regular re-calibration to stay robust against distribution-drift\n",
        "\n"
      ],
      "metadata": {
        "id": "bCZcZdAIdTzg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Static quantization of a model consists of the following steps:\n",
        "\n",
        "#     Fuse modules\n",
        "#     Insert Quant/DeQuant Stubs\n",
        "#     Prepare the fused module (insert observers before and after layers)\n",
        "#     Calibrate the prepared module (pass it representative data)\n",
        "#     Convert the calibrated module (replace with quantized version)\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import copy\n",
        "\n",
        "backend = \"fbgemm\"  # running on a x86 CPU. Use \"qnnpack\" if running on ARM.\n",
        "\n",
        "model = nn.Sequential(\n",
        "     nn.Conv2d(2, 64, 3),\n",
        "     nn.ReLU(),\n",
        "     nn.Conv2d(64, 128, 3),\n",
        "     nn.ReLU()\n",
        ")"
      ],
      "metadata": {
        "id": "3v3vGj4WaQYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "UaZu_-p7OMgf",
        "outputId": "97e7167b-3973-4b5d-c119-29e38d860d99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'Parameter' object is not callable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3628335316.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melement_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: 'Parameter' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## EAGER MODE\n",
        "m = copy.deepcopy(model)\n",
        "m.eval()\n",
        "\n",
        "\"\"\"Fuse\n",
        "- Inplace fusion replaces the first module in the sequence with the fused module, and the rest with identity modules\n",
        "\"\"\"\n",
        "torch.ao.quantization.fuse_modules(m, ['0','1'], inplace=True) # fuse first Conv-ReLU pair\n",
        "torch.ao.quantization.fuse_modules(m, ['2','3'], inplace=True) # fuse second Conv-ReLU pair\n",
        "\n",
        "\"\"\"Insert stubs\"\"\"\n",
        "m = nn.Sequential(torch.ao.quantization.QuantStub(),\n",
        "                  *m,\n",
        "                  torch.ao.quantization.DeQuantStub())\n",
        "\n",
        "\"\"\"Prepare\"\"\"\n",
        "m.qconfig = torch.ao.quantization.get_default_qconfig(backend)\n",
        "torch.ao.quantization.prepare(m, inplace=True)\n",
        "\n",
        "\"\"\"Calibrate\n",
        "- This example uses random data for convenience. Use representative (validation) data instead.\n",
        "\"\"\"\n",
        "with torch.inference_mode():\n",
        "  for _ in range(10):\n",
        "    x = torch.rand(1, 2, 28, 28)\n",
        "    m(x)\n",
        "\n",
        "\"\"\"Convert\"\"\"\n",
        "torch.ao.quantization.convert(m, inplace=True)\n",
        "\n",
        "\"\"\"Check\"\"\"\n",
        "print(m[1].weight().element_size()) # 1 byte instead of 4 bytes for FP32"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgNoxdlneyuM",
        "outputId": "bb10ac74-9428-437e-f867-36097e1a4860"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-213743822.py:18: DeprecationWarning: torch.ao.quantization is deprecated and will be removed in 2.10. \n",
            "For migrations of users: \n",
            "1. Eager mode quantization (torch.ao.quantization.quantize, torch.ao.quantization.quantize_dynamic), please migrate to use torchao eager mode quantize_ API instead \n",
            "2. FX graph mode quantization (torch.ao.quantization.quantize_fx.prepare_fx,torch.ao.quantization.quantize_fx.convert_fx, please migrate to use torchao pt2e quantization API instead (prepare_pt2e, convert_pt2e) \n",
            "3. pt2e quantization has been migrated to torchao (https://github.com/pytorch/ao/tree/main/torchao/quantization/pt2e) \n",
            "see https://github.com/pytorch/ao/issues/2259 for more details\n",
            "  torch.ao.quantization.prepare(m, inplace=True)\n",
            "/tmp/ipython-input-213743822.py:29: DeprecationWarning: torch.ao.quantization is deprecated and will be removed in 2.10. \n",
            "For migrations of users: \n",
            "1. Eager mode quantization (torch.ao.quantization.quantize, torch.ao.quantization.quantize_dynamic), please migrate to use torchao eager mode quantize_ API instead \n",
            "2. FX graph mode quantization (torch.ao.quantization.quantize_fx.prepare_fx,torch.ao.quantization.quantize_fx.convert_fx, please migrate to use torchao pt2e quantization API instead (prepare_pt2e, convert_pt2e) \n",
            "3. pt2e quantization has been migrated to torchao (https://github.com/pytorch/ao/tree/main/torchao/quantization/pt2e) \n",
            "see https://github.com/pytorch/ao/issues/2259 for more details\n",
            "  torch.ao.quantization.convert(m, inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m[1].weight()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmyPkO1Bi-Tw",
        "outputId": "dd350a35-e4c4-46da-950a-536bfe096324"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[-0.0933, -0.0842, -0.0275],\n",
              "          [ 0.0439,  0.0714, -0.0146],\n",
              "          [-0.2342, -0.1501,  0.1592]],\n",
              "\n",
              "         [[ 0.0037, -0.0073,  0.0384],\n",
              "          [ 0.0860, -0.1574,  0.1043],\n",
              "          [ 0.0622,  0.0842,  0.0238]]],\n",
              "\n",
              "\n",
              "        [[[ 0.1001, -0.1001, -0.1244],\n",
              "          [ 0.0873, -0.0901, -0.1545],\n",
              "          [-0.1230, -0.1831, -0.1631]],\n",
              "\n",
              "         [[-0.0429,  0.0229, -0.1302],\n",
              "          [-0.0501,  0.0300,  0.0772],\n",
              "          [-0.1530,  0.1001,  0.0529]]],\n",
              "\n",
              "\n",
              "        [[[ 0.0224,  0.1222,  0.0671],\n",
              "          [ 0.1136,  0.0826, -0.1584],\n",
              "          [ 0.1205,  0.1859, -0.1136]],\n",
              "\n",
              "         [[-0.2204,  0.2135,  0.1308],\n",
              "          [ 0.2014,  0.1532,  0.0465],\n",
              "          [-0.2066, -0.0207, -0.1153]]],\n",
              "\n",
              "\n",
              "        ...,\n",
              "\n",
              "\n",
              "        [[[-0.1481, -0.1252,  0.1816],\n",
              "          [ 0.1869,  0.1728, -0.0599],\n",
              "          [ 0.1199, -0.2169, -0.0176]],\n",
              "\n",
              "         [[-0.0194,  0.1358, -0.0071],\n",
              "          [-0.0212, -0.0282,  0.0000],\n",
              "          [-0.0952, -0.0758, -0.2257]]],\n",
              "\n",
              "\n",
              "        [[[ 0.0545,  0.0514, -0.1262],\n",
              "          [ 0.1573, -0.0498, -0.0016],\n",
              "          [ 0.0717, -0.0265, -0.1854]],\n",
              "\n",
              "         [[-0.1682,  0.0343,  0.0093],\n",
              "          [-0.1651, -0.1340, -0.1090],\n",
              "          [-0.0016,  0.1978,  0.1978]]],\n",
              "\n",
              "\n",
              "        [[[ 0.1866, -0.0879, -0.1956],\n",
              "          [-0.1471,  0.2279,  0.0574],\n",
              "          [-0.1112, -0.1812, -0.2189]],\n",
              "\n",
              "         [[-0.0269, -0.0054,  0.1292],\n",
              "          [-0.0126,  0.1453, -0.0144],\n",
              "          [ 0.0449,  0.0431, -0.0969]]]], size=(64, 2, 3, 3),\n",
              "       dtype=torch.qint8, quantization_scheme=torch.per_channel_affine,\n",
              "       scale=tensor([0.0018, 0.0014, 0.0017, 0.0018, 0.0017, 0.0017, 0.0018, 0.0018, 0.0015,\n",
              "        0.0015, 0.0018, 0.0018, 0.0016, 0.0015, 0.0018, 0.0018, 0.0018, 0.0018,\n",
              "        0.0017, 0.0018, 0.0017, 0.0018, 0.0018, 0.0018, 0.0018, 0.0018, 0.0018,\n",
              "        0.0017, 0.0017, 0.0018, 0.0015, 0.0018, 0.0018, 0.0018, 0.0018, 0.0018,\n",
              "        0.0018, 0.0016, 0.0018, 0.0015, 0.0017, 0.0017, 0.0018, 0.0018, 0.0018,\n",
              "        0.0018, 0.0018, 0.0017, 0.0017, 0.0018, 0.0018, 0.0018, 0.0017, 0.0018,\n",
              "        0.0014, 0.0018, 0.0017, 0.0014, 0.0018, 0.0018, 0.0017, 0.0018, 0.0016,\n",
              "        0.0018], dtype=torch.float64),\n",
              "       zero_point=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
              "       axis=0)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## FX GRAPH\n",
        "from torch.ao.quantization import quantize_fx\n",
        "\n",
        "m = copy.deepcopy(model)\n",
        "m.eval()\n",
        "qconfig_dict = {\"\": torch.ao.quantization.get_default_qconfig(backend)}\n",
        "\n",
        "# Prepare\n",
        "example_inputs = (torch.randn(1, 3, 224, 224),)\n",
        "model_prepared = quantize_fx.prepare_fx(m, qconfig_dict, example_inputs)\n",
        "\n",
        "# Calibrate - Use representative (validation) data.\n",
        "with torch.inference_mode():\n",
        "  for _ in range(10):\n",
        "    x = torch.rand(1, 2, 28, 28)\n",
        "    model_prepared(x)\n",
        "\n",
        "# quantize\n",
        "model_quantized = quantize_fx.convert_fx(model_prepared)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8a-ihuEe13L",
        "outputId": "3e0b71df-9e29-4186-8c88-0a06701c85d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-750729956.py:10: DeprecationWarning: torch.ao.quantization is deprecated and will be removed in 2.10. \n",
            "For migrations of users: \n",
            "1. Eager mode quantization (torch.ao.quantization.quantize, torch.ao.quantization.quantize_dynamic), please migrate to use torchao eager mode quantize_ API instead \n",
            "2. FX graph mode quantization (torch.ao.quantization.quantize_fx.prepare_fx,torch.ao.quantization.quantize_fx.convert_fx, please migrate to use torchao pt2e quantization API instead (prepare_pt2e, convert_pt2e) \n",
            "3. pt2e quantization has been migrated to torchao (https://github.com/pytorch/ao/tree/main/torchao/quantization/pt2e) \n",
            "see https://github.com/pytorch/ao/issues/2259 for more details\n",
            "  model_prepared = quantize_fx.prepare_fx(m, qconfig_dict, example_inputs)\n",
            "/usr/local/lib/python3.12/dist-packages/torch/ao/quantization/quantize_fx.py:146: FutureWarning: Passing a QConfig dictionary to prepare is deprecated and will not be supported in a future version. Please pass in a QConfigMapping instead.\n",
            "  prepared = prepare(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/ao/quantization/observer.py:246: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-750729956.py:19: DeprecationWarning: torch.ao.quantization is deprecated and will be removed in 2.10. \n",
            "For migrations of users: \n",
            "1. Eager mode quantization (torch.ao.quantization.quantize, torch.ao.quantization.quantize_dynamic), please migrate to use torchao eager mode quantize_ API instead \n",
            "2. FX graph mode quantization (torch.ao.quantization.quantize_fx.prepare_fx,torch.ao.quantization.quantize_fx.convert_fx, please migrate to use torchao pt2e quantization API instead (prepare_pt2e, convert_pt2e) \n",
            "3. pt2e quantization has been migrated to torchao (https://github.com/pytorch/ao/tree/main/torchao/quantization/pt2e) \n",
            "see https://github.com/pytorch/ao/issues/2259 for more details\n",
            "  model_quantized = quantize_fx.convert_fx(model_prepared)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SENSITIVITY ANALYSIS"
      ],
      "metadata": {
        "id": "wT-qggJdacLr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ONE-AT-A-TIME SENSITIVITY ANALYSIS\n",
        "\n",
        "for quantized_layer, _ in model.named_modules():\n",
        "  print(\"Only quantizing layer: \", quantized_layer)\n",
        "\n",
        "  # The module_name key allows module-specific qconfigs.\n",
        "  qconfig_dict = {\"\": None,\n",
        "  \"module_name\":[(quantized_layer, torch.quantization.get_default_qconfig(backend))]}\n",
        "\n",
        "  example_inputs = (torch.randn(1, 3, 224, 224),)\n",
        "  model_prepared = quantize_fx.prepare_fx(model, qconfig_dict, example_inputs)\n",
        "  # calibrate\n",
        "  model_quantized = quantize_fx.convert_fx(model_prepared)\n",
        "  # evaluate(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tD294D_Tac3K",
        "outputId": "f05c158c-b2fe-48a9-a6f6-ac6f0d7f7bac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Only quantizing layer:  \n",
            "Only quantizing layer:  0\n",
            "Only quantizing layer:  1\n",
            "Only quantizing layer:  2\n",
            "Only quantizing layer:  3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1147990886.py:11: DeprecationWarning: torch.ao.quantization is deprecated and will be removed in 2.10. \n",
            "For migrations of users: \n",
            "1. Eager mode quantization (torch.ao.quantization.quantize, torch.ao.quantization.quantize_dynamic), please migrate to use torchao eager mode quantize_ API instead \n",
            "2. FX graph mode quantization (torch.ao.quantization.quantize_fx.prepare_fx,torch.ao.quantization.quantize_fx.convert_fx, please migrate to use torchao pt2e quantization API instead (prepare_pt2e, convert_pt2e) \n",
            "3. pt2e quantization has been migrated to torchao (https://github.com/pytorch/ao/tree/main/torchao/quantization/pt2e) \n",
            "see https://github.com/pytorch/ao/issues/2259 for more details\n",
            "  model_prepared = quantize_fx.prepare_fx(model, qconfig_dict, example_inputs)\n",
            "/tmp/ipython-input-1147990886.py:13: DeprecationWarning: torch.ao.quantization is deprecated and will be removed in 2.10. \n",
            "For migrations of users: \n",
            "1. Eager mode quantization (torch.ao.quantization.quantize, torch.ao.quantization.quantize_dynamic), please migrate to use torchao eager mode quantize_ API instead \n",
            "2. FX graph mode quantization (torch.ao.quantization.quantize_fx.prepare_fx,torch.ao.quantization.quantize_fx.convert_fx, please migrate to use torchao pt2e quantization API instead (prepare_pt2e, convert_pt2e) \n",
            "3. pt2e quantization has been migrated to torchao (https://github.com/pytorch/ao/tree/main/torchao/quantization/pt2e) \n",
            "see https://github.com/pytorch/ao/issues/2259 for more details\n",
            "  model_quantized = quantize_fx.convert_fx(model_prepared)\n",
            "/usr/local/lib/python3.12/dist-packages/torch/ao/quantization/observer.py:1343: UserWarning: must run observer before calling calculate_qparams.                                    Returning default scale and zero point \n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Numeric Suite - https://pytorch.org/tutorials/prototype/numeric_suite_tutorial.html"
      ],
      "metadata": {
        "id": "9dXAIoKwbCFl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "import os\n",
        "import torch.ao.quantization\n",
        "import torch.ao.ns._numeric_suite as ns\n",
        "from torch.ao.quantization import (\n",
        "    default_eval_fn,\n",
        "    default_qconfig,\n",
        "    quantize,\n",
        ")"
      ],
      "metadata": {
        "id": "N7FfZtQdbV90"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "float_model = torchvision.models.quantization.resnet18(pretrained=True, quantize=False)\n",
        "float_model.to('cpu')\n",
        "float_model.eval()\n",
        "float_model.fuse_model()\n",
        "float_model.qconfig = torch.quantization.default_qconfig\n",
        "img_data = (torch.rand(2, 3, 10, 10, dtype=torch.float), torch.randint(0, 1, (2,), dtype=torch.long))\n",
        "qmodel = quantize(float_model, default_eval_fn, [[img_data]], inplace=False)"
      ],
      "metadata": {
        "id": "jm-ESg6obWWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_error(x, y):\n",
        "    Ps = torch.norm(x)\n",
        "    Pn = torch.norm(x - y)\n",
        "    return 20 * torch.log10(Ps/Pn)\n",
        "\n",
        "wt_compare_dict = ns.compare_weights(float_model.state_dict(), qmodel.state_dict())\n",
        "for key in wt_compare_dict:\n",
        "    print(key, compute_error(wt_compare_dict[key]['float'], wt_compare_dict[key]['quantized'].dequantize()))\n",
        "\n",
        "print(\"---\")\n",
        "\n",
        "act_compare_dict = ns.compare_model_outputs(float_model, qmodel, img_data[0])\n",
        "for key in act_compare_dict:\n",
        "    print(key, compute_error(act_compare_dict[key]['float'][0], act_compare_dict[key]['quantized'][0].dequantize()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKZEOpfPbMNu",
        "outputId": "4c74f046-1594-4f5b-cfd7-38b51f329a1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conv1.weight tensor(31.6638)\n",
            "layer1.0.conv1.weight tensor(30.6450)\n",
            "layer1.0.conv2.weight tensor(31.1528)\n",
            "layer1.1.conv1.weight tensor(32.1438)\n",
            "layer1.1.conv2.weight tensor(31.2477)\n",
            "layer2.0.conv1.weight tensor(30.9890)\n",
            "layer2.0.conv2.weight tensor(28.8233)\n",
            "layer2.0.downsample.0.weight tensor(31.5558)\n",
            "layer2.1.conv1.weight tensor(30.7668)\n",
            "layer2.1.conv2.weight tensor(28.4516)\n",
            "layer3.0.conv1.weight tensor(30.9247)\n",
            "layer3.0.conv2.weight tensor(26.6841)\n",
            "layer3.0.downsample.0.weight tensor(28.7825)\n",
            "layer3.1.conv1.weight tensor(28.9707)\n",
            "layer3.1.conv2.weight tensor(25.6784)\n",
            "layer4.0.conv1.weight tensor(26.8495)\n",
            "layer4.0.conv2.weight tensor(25.8394)\n",
            "layer4.0.downsample.0.weight tensor(28.6355)\n",
            "layer4.1.conv1.weight tensor(26.8758)\n",
            "layer4.1.conv2.weight tensor(28.4319)\n",
            "fc._packed_params._packed_params tensor(32.6505)\n",
            "---\n",
            "conv1.stats tensor(37.4411, grad_fn=<MulBackward0>)\n",
            "layer1.0.conv1.stats tensor(29.6032, grad_fn=<MulBackward0>)\n",
            "layer1.0.conv2.stats tensor(28.3895, grad_fn=<MulBackward0>)\n",
            "layer1.0.add_relu.stats tensor(31.8408, grad_fn=<MulBackward0>)\n",
            "layer1.1.conv1.stats tensor(29.1966, grad_fn=<MulBackward0>)\n",
            "layer1.1.conv2.stats tensor(25.3061, grad_fn=<MulBackward0>)\n",
            "layer1.1.add_relu.stats tensor(28.9989, grad_fn=<MulBackward0>)\n",
            "layer2.0.conv1.stats tensor(26.2547, grad_fn=<MulBackward0>)\n",
            "layer2.0.conv2.stats tensor(26.3159, grad_fn=<MulBackward0>)\n",
            "layer2.0.downsample.0.stats tensor(21.8628, grad_fn=<MulBackward0>)\n",
            "layer2.0.add_relu.stats tensor(25.7588, grad_fn=<MulBackward0>)\n",
            "layer2.1.conv1.stats tensor(25.3852, grad_fn=<MulBackward0>)\n",
            "layer2.1.conv2.stats tensor(24.6284, grad_fn=<MulBackward0>)\n",
            "layer2.1.add_relu.stats tensor(25.7878, grad_fn=<MulBackward0>)\n",
            "layer3.0.conv1.stats tensor(26.6457, grad_fn=<MulBackward0>)\n",
            "layer3.0.conv2.stats tensor(26.6580, grad_fn=<MulBackward0>)\n",
            "layer3.0.downsample.0.stats tensor(24.8511, grad_fn=<MulBackward0>)\n",
            "layer3.0.add_relu.stats tensor(24.7550, grad_fn=<MulBackward0>)\n",
            "layer3.1.conv1.stats tensor(29.9616, grad_fn=<MulBackward0>)\n",
            "layer3.1.conv2.stats tensor(25.6695, grad_fn=<MulBackward0>)\n",
            "layer3.1.add_relu.stats tensor(25.3829, grad_fn=<MulBackward0>)\n",
            "layer4.0.conv1.stats tensor(27.0312, grad_fn=<MulBackward0>)\n",
            "layer4.0.conv2.stats tensor(27.1815, grad_fn=<MulBackward0>)\n",
            "layer4.0.downsample.0.stats tensor(22.7665, grad_fn=<MulBackward0>)\n",
            "layer4.0.add_relu.stats tensor(21.4375, grad_fn=<MulBackward0>)\n",
            "layer4.1.conv1.stats tensor(27.0220, grad_fn=<MulBackward0>)\n",
            "layer4.1.conv2.stats tensor(18.7704, grad_fn=<MulBackward0>)\n",
            "layer4.1.add_relu.stats tensor(19.1204, grad_fn=<MulBackward0>)\n",
            "fc.stats tensor(21.6713, grad_fn=<MulBackward0>)\n",
            "quant.stats tensor(48.0328)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "f = wt_compare_dict['conv1.weight']['float'].flatten()\n",
        "plt.hist(f, bins = 100)\n",
        "\n",
        "q = wt_compare_dict['conv1.weight']['quantized'].flatten().dequantize()\n",
        "plt.hist(q, bins = 100)\n",
        "plt.title(\"Quantized model weights of conv1\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "eYUaWoAyeL7a",
        "outputId": "d6706d68-1d63-42f4-ee3f-05a519ad46b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RECOMMENDATIONS FOR YOUR WORKFLOW"
      ],
      "metadata": {
        "id": "_YQ7S0iIb8cz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://drive.google.com/uc?export=view&id=1ij7GElwiKFNmJ221aKpkDRwMj5i-2DLh)"
      ],
      "metadata": {
        "id": "P-cxT3iwb9jU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Large (10M+ parameters) models are more robust to quantization error\n",
        "*   Quantizing a model from a FP32 checkpoint provides better accuracy than training an INT8 model from scratch\n",
        "*   Dynamic Quantization is an easy first step, especially if your model has many Linear or Recurrent layers\n",
        "*   Use symmetric-per-channel quantization with MinMax observers for quantizing weights. Use affine-per-tensor quantization with MovingAverageMinMax observers for quantizing activations\n",
        "*   Use metrics like SQNR to identify which layers are most suscpetible to quantization error. Turn off quantization on these layers"
      ],
      "metadata": {
        "id": "vBbyE61acqr6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Eager mode https://pytorch.org/docs/stable/quantization.html#eager-mode-quantization\n",
        "\n",
        "\n",
        "\n",
        "*   https://pytorch.org/docs/stable/quantization.html#post-training-dynamic-quantization\n",
        "*   https://pytorch.org/docs/stable/quantization.html#post-training-static-quantization\n",
        "\n",
        "\n",
        "FX Graph https://pytorch.org/docs/stable/quantization.html#prototype-fx-graph-mode-quantization\n",
        "\n",
        "\n",
        "\n",
        "*   https://pytorch.org/tutorials/prototype/fx_graph_mode_ptq_static.html\n",
        "*   https://pytorch.org/tutorials/prototype/fx_graph_mode_ptq_dynamic.html\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dZkMfDNCp9f1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## New forkflow with torchao\n",
        "\n"
      ],
      "metadata": {
        "id": "za9ziysYh-7V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchao"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHc-7SBJiWid",
        "outputId": "743889a9-28f3-4a2b-a2e0-027d3abed8f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchao in /usr/local/lib/python3.12/dist-packages (0.10.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import torch\n",
        "\n",
        "class ToyLinearModel(torch.nn.Module):\n",
        "    def __init__(self, m: int, n: int, k: int):\n",
        "        super().__init__()\n",
        "        self.linear1 = torch.nn.Linear(m, n, bias=False)\n",
        "        self.linear2 = torch.nn.Linear(n, k, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear1(x)\n",
        "        x = self.linear2(x)\n",
        "        return x\n",
        "\n",
        "model = ToyLinearModel(1024, 1024, 1024).eval()\n",
        "\n",
        "# Optional: compile model for faster inference and generation\n",
        "model = torch.compile(model, mode=\"max-autotune\", fullgraph=True)\n",
        "model_f32 = copy.deepcopy(model)\n"
      ],
      "metadata": {
        "id": "6LP_lwV2iGXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchao.quantization import Int4DynamicActivationInt4WeightConfig, quantize_\n",
        "quantize_(model, Int4DynamicActivationInt4WeightConfig())"
      ],
      "metadata": {
        "id": "2cYxfwkt-xrX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchao.utils import (\n",
        "    benchmark_model,\n",
        "    unwrap_tensor_subclass,\n",
        ")\n",
        "\n",
        "num_runs = 100\n",
        "torch._dynamo.reset()\n",
        "example_inputs = (torch.randn(1, 1024, dtype=torch.float32),)\n",
        "f32_time = benchmark_model(model_f32, num_runs, example_inputs)\n",
        "int4_time = benchmark_model(model, num_runs, example_inputs)\n",
        "\n",
        "print(\"f32 mean time: %0.3f ms\" % f32_time)\n",
        "print(\"int4 mean time: %0.3f ms\" % int4_time)\n",
        "print(\"speedup: %0.1fx\" % (f32_time / int4_time))"
      ],
      "metadata": {
        "id": "XbGjMaxGj20y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22e92824-8902-400b-c5d9-10366d82920f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "W1027 10:36:26.360000 1094 torch/utils/cpp_extension.py:118] [0/0] No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f32 mean time: 0.123 ms\n",
            "int4 mean time: 0.162 ms\n",
            "speedup: 0.8x\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "torch.save(model, \"/tmp/int4_model.pt\")\n",
        "torch.save(model_f32, \"/tmp/f32_model.pt\")\n",
        "int4_model_size_mb = os.path.getsize(\"/tmp/int4_model.pt\") / 1024 / 1024\n",
        "f32_model_size_mb = os.path.getsize(\"/tmp/f32_model.pt\") / 1024 / 1024\n",
        "\n",
        "print(\"int4 model size: %.2f MB\" % int4_model_size_mb)\n",
        "\n",
        "print(\"f32 model size: %.2f MB\" % f32_model_size_mb)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWDUskVC-H1z",
        "outputId": "9656c9bc-b85f-49e4-9258-7c92b21848de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "int4 model size: 1.01 MB\n",
            "f32 model size: 8.00 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Neural Network Compression Framework (NNCF)"
      ],
      "metadata": {
        "id": "BI8kSIybQcEQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/openvinotoolkit/nncf"
      ],
      "metadata": {
        "id": "P7q1Gh6YQfhu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29be0508-a8aa-47b6-fb70-b4c415adb0bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'nncf'...\n",
            "remote: Enumerating objects: 47284, done.\u001b[K\n",
            "remote: Counting objects: 100% (6170/6170), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2248/2248), done.\u001b[K\n",
            "remote: Total 47284 (delta 3294), reused 5398 (delta 2909), pack-reused 41114\u001b[K\n",
            "Receiving objects: 100% (47284/47284), 39.55 MiB | 26.35 MiB/s, done.\n",
            "Resolving deltas: 100% (31350/31350), done.\n",
            "Filtering content: 100% (142/142), 32.00 MiB | 18.07 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%capture\n",
        "%cd nncf\n",
        "!pip install .[torch]\n",
        "%cd /content"
      ],
      "metadata": {
        "id": "7inenttGuOti",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d08f9842-921d-4e6f-ec83-5a0373e6553f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/nncf\n",
            "Processing /content/nncf\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pymoo@ git+https://github.com/anyoptimization/pymoo.git@695cb26923903f872c7256a9013609769f3cc2bd (from nncf==2.5.0.dev0+9c30388f)\n",
            "  Cloning https://github.com/anyoptimization/pymoo.git (to revision 695cb26923903f872c7256a9013609769f3cc2bd) to /tmp/pip-install-bhxstqg6/pymoo_e66377a95ce74813841ab1a8bb972ab7\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/anyoptimization/pymoo.git /tmp/pip-install-bhxstqg6/pymoo_e66377a95ce74813841ab1a8bb972ab7\n",
            "  Running command git rev-parse -q --verify 'sha^695cb26923903f872c7256a9013609769f3cc2bd'\n",
            "  Running command git fetch -q https://github.com/anyoptimization/pymoo.git 695cb26923903f872c7256a9013609769f3cc2bd\n",
            "  Running command git checkout -q 695cb26923903f872c7256a9013609769f3cc2bd\n",
            "  Resolved https://github.com/anyoptimization/pymoo.git to commit 695cb26923903f872c7256a9013609769f3cc2bd\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: jsonschema>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from nncf==2.5.0.dev0+9c30388f) (4.19.0)\n",
            "Collecting jstyleson>=0.0.2 (from nncf==2.5.0.dev0+9c30388f)\n",
            "  Downloading jstyleson-0.0.2.tar.gz (2.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: natsort>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from nncf==2.5.0.dev0+9c30388f) (8.4.0)\n",
            "Collecting networkx<=2.8.2,>=2.6 (from nncf==2.5.0.dev0+9c30388f)\n",
            "  Downloading networkx-2.8.2-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ninja<1.11,>=1.10.0.post2 (from nncf==2.5.0.dev0+9c30388f)\n",
            "  Downloading ninja-1.10.2.4-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (120 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m120.7/120.7 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<1.25,>=1.19.1 in /usr/local/lib/python3.10/dist-packages (from nncf==2.5.0.dev0+9c30388f) (1.23.5)\n",
            "Collecting openvino-telemetry>=2023.1.1 (from nncf==2.5.0.dev0+9c30388f)\n",
            "  Downloading openvino_telemetry-2023.1.1-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from nncf==2.5.0.dev0+9c30388f) (23.1)\n",
            "Requirement already satisfied: pandas<2.1,>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from nncf==2.5.0.dev0+9c30388f) (1.5.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from nncf==2.5.0.dev0+9c30388f) (5.9.5)\n",
            "Requirement already satisfied: pydot>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nncf==2.5.0.dev0+9c30388f) (1.4.2)\n",
            "Collecting pyparsing<3.0 (from nncf==2.5.0.dev0+9c30388f)\n",
            "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from nncf==2.5.0.dev0+9c30388f) (1.2.2)\n",
            "Requirement already satisfied: scipy<1.11,>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from nncf==2.5.0.dev0+9c30388f) (1.10.1)\n",
            "Collecting texttable>=1.6.3 (from nncf==2.5.0.dev0+9c30388f)\n",
            "  Downloading texttable-1.6.7-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: tqdm>=4.54.1 in /usr/local/lib/python3.10/dist-packages (from nncf==2.5.0.dev0+9c30388f) (4.66.1)\n",
            "Requirement already satisfied: torch<2.1,>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from nncf==2.5.0.dev0+9c30388f) (2.0.1+cu118)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.2.0->nncf==2.5.0.dev0+9c30388f) (23.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.2.0->nncf==2.5.0.dev0+9c30388f) (2023.7.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.2.0->nncf==2.5.0.dev0+9c30388f) (0.30.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.2.0->nncf==2.5.0.dev0+9c30388f) (0.9.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.1,>=1.1.5->nncf==2.5.0.dev0+9c30388f) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.1,>=1.1.5->nncf==2.5.0.dev0+9c30388f) (2023.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.0->nncf==2.5.0.dev0+9c30388f) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.0->nncf==2.5.0.dev0+9c30388f) (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=1.13.0->nncf==2.5.0.dev0+9c30388f) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=1.13.0->nncf==2.5.0.dev0+9c30388f) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=1.13.0->nncf==2.5.0.dev0+9c30388f) (1.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=1.13.0->nncf==2.5.0.dev0+9c30388f) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=1.13.0->nncf==2.5.0.dev0+9c30388f) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch<2.1,>=1.13.0->nncf==2.5.0.dev0+9c30388f) (3.27.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch<2.1,>=1.13.0->nncf==2.5.0.dev0+9c30388f) (16.0.6)\n",
            "Requirement already satisfied: matplotlib>=3 in /usr/local/lib/python3.10/dist-packages (from pymoo@ git+https://github.com/anyoptimization/pymoo.git@695cb26923903f872c7256a9013609769f3cc2bd->nncf==2.5.0.dev0+9c30388f) (3.7.1)\n",
            "Requirement already satisfied: autograd>=1.4 in /usr/local/lib/python3.10/dist-packages (from pymoo@ git+https://github.com/anyoptimization/pymoo.git@695cb26923903f872c7256a9013609769f3cc2bd->nncf==2.5.0.dev0+9c30388f) (1.6.2)\n",
            "Collecting cma==3.2.2 (from pymoo@ git+https://github.com/anyoptimization/pymoo.git@695cb26923903f872c7256a9013609769f3cc2bd->nncf==2.5.0.dev0+9c30388f)\n",
            "  Downloading cma-3.2.2-py2.py3-none-any.whl (249 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m249.1/249.1 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting alive-progress (from pymoo@ git+https://github.com/anyoptimization/pymoo.git@695cb26923903f872c7256a9013609769f3cc2bd->nncf==2.5.0.dev0+9c30388f)\n",
            "  Downloading alive_progress-3.1.4-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dill (from pymoo@ git+https://github.com/anyoptimization/pymoo.git@695cb26923903f872c7256a9013609769f3cc2bd->nncf==2.5.0.dev0+9c30388f)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Deprecated (from pymoo@ git+https://github.com/anyoptimization/pymoo.git@695cb26923903f872c7256a9013609769f3cc2bd->nncf==2.5.0.dev0+9c30388f)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.10/dist-packages (from autograd>=1.4->pymoo@ git+https://github.com/anyoptimization/pymoo.git@695cb26923903f872c7256a9013609769f3cc2bd->nncf==2.5.0.dev0+9c30388f) (0.18.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->pymoo@ git+https://github.com/anyoptimization/pymoo.git@695cb26923903f872c7256a9013609769f3cc2bd->nncf==2.5.0.dev0+9c30388f) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->pymoo@ git+https://github.com/anyoptimization/pymoo.git@695cb26923903f872c7256a9013609769f3cc2bd->nncf==2.5.0.dev0+9c30388f) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->pymoo@ git+https://github.com/anyoptimization/pymoo.git@695cb26923903f872c7256a9013609769f3cc2bd->nncf==2.5.0.dev0+9c30388f) (4.42.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->pymoo@ git+https://github.com/anyoptimization/pymoo.git@695cb26923903f872c7256a9013609769f3cc2bd->nncf==2.5.0.dev0+9c30388f) (1.4.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->pymoo@ git+https://github.com/anyoptimization/pymoo.git@695cb26923903f872c7256a9013609769f3cc2bd->nncf==2.5.0.dev0+9c30388f) (9.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas<2.1,>=1.1.5->nncf==2.5.0.dev0+9c30388f) (1.16.0)\n",
            "Collecting about-time==4.2.1 (from alive-progress->pymoo@ git+https://github.com/anyoptimization/pymoo.git@695cb26923903f872c7256a9013609769f3cc2bd->nncf==2.5.0.dev0+9c30388f)\n",
            "  Downloading about_time-4.2.1-py3-none-any.whl (13 kB)\n",
            "Collecting grapheme==0.6.0 (from alive-progress->pymoo@ git+https://github.com/anyoptimization/pymoo.git@695cb26923903f872c7256a9013609769f3cc2bd->nncf==2.5.0.dev0+9c30388f)\n",
            "  Downloading grapheme-0.6.0.tar.gz (207 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from Deprecated->pymoo@ git+https://github.com/anyoptimization/pymoo.git@695cb26923903f872c7256a9013609769f3cc2bd->nncf==2.5.0.dev0+9c30388f) (1.14.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<2.1,>=1.13.0->nncf==2.5.0.dev0+9c30388f) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<2.1,>=1.13.0->nncf==2.5.0.dev0+9c30388f) (1.3.0)\n",
            "Building wheels for collected packages: jstyleson, nncf, pymoo, grapheme\n",
            "  Building wheel for jstyleson (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jstyleson: filename=jstyleson-0.0.2-py3-none-any.whl size=2384 sha256=731c8f5d4e87d4b4b37c2c6e764851e58559577e373cdd7ca490376de7c59072\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/51/c6/a1e751db88203e11c6d9ffe4683ca3d8c14b1479639bec1006\n",
            "  Building wheel for nncf (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nncf: filename=nncf-2.5.0.dev0+9c30388f-py3-none-any.whl size=1139920 sha256=11a9ec27c986971b284afe501015fe351dbeab9dedd2788560bfddc44046ed39\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-xho9uta8/wheels/dd/e6/7b/14fe3a58e08fb43dadb909606dbb961f65984f671c4e72abb0\n",
            "  Building wheel for pymoo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pymoo: filename=pymoo-0.6.0.1-cp310-cp310-linux_x86_64.whl size=3225993 sha256=5eb6e5e256d054b4467fe46879cab5790055ab59592a99d8194ca2e78d9db159\n",
            "  Stored in directory: /root/.cache/pip/wheels/30/76/84/56f244b9306940b915c56642523019ec6846a50b9aca36076d\n",
            "  Building wheel for grapheme (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for grapheme: filename=grapheme-0.6.0-py3-none-any.whl size=210079 sha256=2b8e2af51c47ac28afb30241a254a521ce7cd5865ac4188e3457d7bc8794fa93\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/e1/49/37e6bde9886439057450c494a79b0bef8bbe897a54aebfc757\n",
            "Successfully built jstyleson nncf pymoo grapheme\n",
            "Installing collected packages: texttable, openvino-telemetry, ninja, jstyleson, grapheme, pyparsing, networkx, dill, Deprecated, cma, about-time, alive-progress, pymoo, nncf\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.1.1\n",
            "    Uninstalling pyparsing-3.1.1:\n",
            "      Successfully uninstalled pyparsing-3.1.1\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.1\n",
            "    Uninstalling networkx-3.1:\n",
            "      Successfully uninstalled networkx-3.1\n",
            "Successfully installed Deprecated-1.2.14 about-time-4.2.1 alive-progress-3.1.4 cma-3.2.2 dill-0.3.7 grapheme-0.6.0 jstyleson-0.0.2 networkx-2.8.2 ninja-1.10.2.4 nncf-2.5.0.dev0+9c30388f openvino-telemetry-2023.1.1 pymoo-0.6.0.1 pyparsing-2.4.7 texttable-1.6.7\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pyparsing"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import nncf.torch  # Important - must be imported before any other external package that depends on torch"
      ],
      "metadata": {
        "id": "VwLu99qZ3IEl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c017febe-b1b2-4e43-9ec1-d4a520c7ffd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:nncf:NNCF initialized successfully. Supported frameworks detected: torch, tensorflow\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/openvinotoolkit/nncf/tree/develop\n",
        "https://github.com/openvinotoolkit/nncf/blob/develop/docs/compression_algorithms/Quantization.md\n",
        "https://github.com/openvinotoolkit/nncf/blob/develop/examples/torch/classification/configs/quantization/inception_v3_imagenet_int8.json\n",
        "\n",
        "https://dev-discuss.pytorch.org/t/torch-ao-quantization-migration-plan/2810\n",
        "https://docs.pytorch.org/ao/stable"
      ],
      "metadata": {
        "id": "XwXZ_Te7El1C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "** **:  Post Training Quantization   float32 torch2     .        .          (.  ).         SENSITIVITY .      .     / ."
      ],
      "metadata": {
        "id": "Ysq3_CdFoNuu"
      }
    }
  ]
}