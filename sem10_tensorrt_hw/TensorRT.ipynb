{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# TensorRT"
      ],
      "metadata": {
        "id": "TuDotMn6HTUQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Установка зависимостей"
      ],
      "metadata": {
        "id": "30JaAa7DJ3_D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip list | grep torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wYjQs3e6RWz",
        "outputId": "20f2b5ba-a650-4786-89ab-dedcc1744a9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch                                    2.8.0+cu126\n",
            "torchao                                  0.10.0\n",
            "torchaudio                               2.8.0+cu126\n",
            "torchdata                                0.11.0\n",
            "torchsummary                             1.5.1\n",
            "torchtune                                0.6.1\n",
            "torchvision                              0.23.0+cu126\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "HzqMCXd7KCwT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2dbfce62-8917-4f91-aa12-b283ea51f291"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorrt\n",
            "  Downloading tensorrt-10.13.3.9.tar.gz (40 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/40.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tensorrt_cu13==10.13.3.9 (from tensorrt)\n",
            "  Downloading tensorrt_cu13-10.13.3.9.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tensorrt_cu13_libs==10.13.3.9 (from tensorrt_cu13==10.13.3.9->tensorrt)\n",
            "  Downloading tensorrt_cu13_libs-10.13.3.9.tar.gz (706 bytes)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tensorrt_cu13_bindings==10.13.3.9 (from tensorrt_cu13==10.13.3.9->tensorrt)\n",
            "  Downloading tensorrt_cu13_bindings-10.13.3.9-cp312-none-manylinux_2_28_x86_64.whl.metadata (606 bytes)\n",
            "Collecting nvidia-cuda-runtime-cu13 (from tensorrt_cu13_libs==10.13.3.9->tensorrt_cu13==10.13.3.9->tensorrt)\n",
            "  Downloading nvidia_cuda_runtime_cu13-0.0.1.tar.gz (1.4 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Downloading tensorrt_cu13_bindings-10.13.3.9-cp312-none-manylinux_2_28_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: tensorrt, tensorrt_cu13, tensorrt_cu13_libs, nvidia-cuda-runtime-cu13\n",
            "  Building wheel for tensorrt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorrt: filename=tensorrt-10.13.3.9-py2.py3-none-any.whl size=46401 sha256=6516fbbe155abf908c28d13cdc45d2cc7f8d817eb551d34fae3e36cefa598950\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/aa/b0/561559321c1659e43c5a6661986c3072f9c383efeeaaffb1a5\n",
            "  Building wheel for tensorrt_cu13 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorrt_cu13: filename=tensorrt_cu13-10.13.3.9-py2.py3-none-any.whl size=17436 sha256=d113087bef5edb4b1f57221970b31fddb8993fa18b0521dd0c3c97d56f387ef9\n",
            "  Stored in directory: /root/.cache/pip/wheels/df/4a/b2/ebfc5437a397c53faff0dca4a36c096d4b7d2b7436a2707e60\n",
            "  Building wheel for tensorrt_cu13_libs (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorrt_cu13_libs: filename=tensorrt_cu13_libs-10.13.3.9-py2.py3-none-manylinux_2_28_x86_64.whl size=2740897716 sha256=19a54f2106f7d9496433a01a596fa4e363f58901110306abe1ce7b6e9617c6a7\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/c2/ab/e79d384901e98797feb52a9ef4e0bbff65c0732f313bfa604f\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for nvidia-cuda-runtime-cu13 \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for nvidia-cuda-runtime-cu13 (pyproject.toml) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31m  ERROR: Failed building wheel for nvidia-cuda-runtime-cu13\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully built tensorrt tensorrt_cu13 tensorrt_cu13_libs\n",
            "Failed to build nvidia-cuda-runtime-cu13\n",
            "\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (nvidia-cuda-runtime-cu13)\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmBOulhT64vR",
        "outputId": "f06cd57d-3dad-48a9-b0ec-73fafbbed502"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-pyindex\n",
            "  Downloading nvidia-pyindex-1.0.9.tar.gz (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: nvidia-pyindex\n",
            "  Building wheel for nvidia-pyindex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nvidia-pyindex: filename=nvidia_pyindex-1.0.9-py3-none-any.whl size=8419 sha256=672a6ec9f9a30b6dc67f7a62b530736f953280fa6bd6d73be54b68dddbbe8929\n",
            "  Stored in directory: /root/.cache/pip/wheels/eb/2d/7f/d86cb060a9c51fb933aa4fe0d2f73ffe8df2bd0b58d3d2bba4\n",
            "Successfully built nvidia-pyindex\n",
            "Installing collected packages: nvidia-pyindex\n",
            "Successfully installed nvidia-pyindex-1.0.9\n",
            "Collecting nvidia-tensorrt\n",
            "  Downloading nvidia_tensorrt-99.0.0-py3-none-manylinux_2_17_x86_64.whl.metadata (596 bytes)\n",
            "Collecting tensorrt (from nvidia-tensorrt)\n",
            "  Using cached tensorrt-10.13.3.9-py2.py3-none-any.whl\n",
            "Collecting tensorrt-cu13==10.13.3.9 (from tensorrt->nvidia-tensorrt)\n",
            "  Using cached tensorrt_cu13-10.13.3.9-py2.py3-none-any.whl\n",
            "Collecting tensorrt-cu13-libs==10.13.3.9 (from tensorrt-cu13==10.13.3.9->tensorrt->nvidia-tensorrt)\n",
            "  Using cached tensorrt_cu13_libs-10.13.3.9-py2.py3-none-manylinux_2_28_x86_64.whl\n",
            "Collecting tensorrt-cu13-bindings==10.13.3.9 (from tensorrt-cu13==10.13.3.9->tensorrt->nvidia-tensorrt)\n",
            "  Using cached tensorrt_cu13_bindings-10.13.3.9-cp312-none-manylinux_2_28_x86_64.whl.metadata (606 bytes)\n",
            "Collecting nvidia-cuda-runtime-cu13 (from tensorrt-cu13-libs==10.13.3.9->tensorrt-cu13==10.13.3.9->tensorrt->nvidia-tensorrt)\n",
            "  Using cached nvidia_cuda_runtime_cu13-0.0.1.tar.gz (1.4 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Downloading nvidia_tensorrt-99.0.0-py3-none-manylinux_2_17_x86_64.whl (17 kB)\n",
            "Using cached tensorrt_cu13_bindings-10.13.3.9-cp312-none-manylinux_2_28_x86_64.whl (1.2 MB)\n",
            "Building wheels for collected packages: nvidia-cuda-runtime-cu13\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for nvidia-cuda-runtime-cu13 \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for nvidia-cuda-runtime-cu13 (pyproject.toml) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31m  ERROR: Failed building wheel for nvidia-cuda-runtime-cu13\u001b[0m\u001b[31m\n",
            "\u001b[0mFailed to build nvidia-cuda-runtime-cu13\n",
            "\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (nvidia-cuda-runtime-cu13)\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install torch-tensorrt==2.8.0 -f https://github.com/pytorch/TensorRT/releases/expanded_assets/2.8.0\n",
        "!pip install -U \"nvidia-modelopt[all]\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BjbB2JHo6-3A",
        "outputId": "c48cef8e-dd2f-4c8f-de52-2bb9cfde96ca"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://github.com/pytorch/TensorRT/releases/expanded_assets/2.8.0\n",
            "Collecting torch-tensorrt==2.8.0\n",
            "  Downloading torch_tensorrt-2.8.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_34_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: packaging>=23 in /usr/local/lib/python3.12/dist-packages (from torch-tensorrt==2.8.0) (25.0)\n",
            "Requirement already satisfied: typing-extensions>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from torch-tensorrt==2.8.0) (4.15.0)\n",
            "Collecting dllist (from torch-tensorrt==2.8.0)\n",
            "  Downloading dllist-2.0.0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: torch<2.9.0,>=2.8.0 in /usr/local/lib/python3.12/dist-packages (from torch-tensorrt==2.8.0) (2.8.0+cu126)\n",
            "Collecting tensorrt<10.13.0,>=10.12.0 (from torch-tensorrt==2.8.0)\n",
            "  Downloading tensorrt-10.12.0.36.tar.gz (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.7/40.7 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tensorrt-cu12-bindings<10.13.0,>=10.12.0 (from torch-tensorrt==2.8.0)\n",
            "  Downloading tensorrt_cu12_bindings-10.12.0.36-cp312-none-manylinux_2_28_x86_64.whl.metadata (607 bytes)\n",
            "Collecting tensorrt-cu12-libs<10.13.0,>=10.12.0 (from torch-tensorrt==2.8.0)\n",
            "  Downloading tensorrt_cu12_libs-10.12.0.36.tar.gz (709 bytes)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch-tensorrt==2.8.0) (2.0.2)\n",
            "Collecting tensorrt_cu12==10.12.0.36 (from tensorrt<10.13.0,>=10.12.0->torch-tensorrt==2.8.0)\n",
            "  Downloading tensorrt_cu12-10.12.0.36.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12 in /usr/local/lib/python3.12/dist-packages (from tensorrt-cu12-libs<10.13.0,>=10.12.0->torch-tensorrt==2.8.0) (12.6.77)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<2.9.0,>=2.8.0->torch-tensorrt==2.8.0) (3.20.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<2.9.0,>=2.8.0->torch-tensorrt==2.8.0) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<2.9.0,>=2.8.0->torch-tensorrt==2.8.0) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch<2.9.0,>=2.8.0->torch-tensorrt==2.8.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<2.9.0,>=2.8.0->torch-tensorrt==2.8.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch<2.9.0,>=2.8.0->torch-tensorrt==2.8.0) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<2.9.0,>=2.8.0->torch-tensorrt==2.8.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<2.9.0,>=2.8.0->torch-tensorrt==2.8.0) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<2.9.0,>=2.8.0->torch-tensorrt==2.8.0) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<2.9.0,>=2.8.0->torch-tensorrt==2.8.0) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<2.9.0,>=2.8.0->torch-tensorrt==2.8.0) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<2.9.0,>=2.8.0->torch-tensorrt==2.8.0) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<2.9.0,>=2.8.0->torch-tensorrt==2.8.0) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<2.9.0,>=2.8.0->torch-tensorrt==2.8.0) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<2.9.0,>=2.8.0->torch-tensorrt==2.8.0) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch<2.9.0,>=2.8.0->torch-tensorrt==2.8.0) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<2.9.0,>=2.8.0->torch-tensorrt==2.8.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<2.9.0,>=2.8.0->torch-tensorrt==2.8.0) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<2.9.0,>=2.8.0->torch-tensorrt==2.8.0) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch<2.9.0,>=2.8.0->torch-tensorrt==2.8.0) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<2.9.0,>=2.8.0->torch-tensorrt==2.8.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<2.9.0,>=2.8.0->torch-tensorrt==2.8.0) (3.0.3)\n",
            "Downloading torch_tensorrt-2.8.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_34_x86_64.whl (15.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.1/15.1 MB\u001b[0m \u001b[31m67.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorrt_cu12_bindings-10.12.0.36-cp312-none-manylinux_2_28_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m76.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dllist-2.0.0-py3-none-any.whl (5.7 kB)\n",
            "Building wheels for collected packages: tensorrt, tensorrt_cu12, tensorrt-cu12-libs\n",
            "  Building wheel for tensorrt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorrt: filename=tensorrt-10.12.0.36-py2.py3-none-any.whl size=46638 sha256=3def4fc0c33b906e26797a8902cf6578b25c210a6b77730fcca9e473881d45ed\n",
            "  Stored in directory: /root/.cache/pip/wheels/0e/d5/2f/cc5e3e56d49c61a02a7a8313f37db27d9af00e7f3463ed33e7\n",
            "  Building wheel for tensorrt_cu12 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorrt_cu12: filename=tensorrt_cu12-10.12.0.36-py2.py3-none-any.whl size=17480 sha256=708b6ac64be8000eaf601569a4ea55648493c3a05567df3bd5961c9d6553aaf5\n",
            "  Stored in directory: /root/.cache/pip/wheels/76/f7/e4/64a0965dcc74c067cee07482ef03cc18add0def626fb0ebc1c\n",
            "  Building wheel for tensorrt-cu12-libs (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorrt-cu12-libs: filename=tensorrt_cu12_libs-10.12.0.36-py2.py3-none-manylinux_2_28_x86_64.whl size=3095483544 sha256=3910039e1d49de0edfdc8bf273e40ad4b85a9d57c7c383fe0e22f75417df9610\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/8f/cb/35c0a5f8d17ece1927e42f2c49108ec506fd79b8e00490d416\n",
            "Successfully built tensorrt tensorrt_cu12 tensorrt-cu12-libs\n",
            "Installing collected packages: tensorrt-cu12-bindings, tensorrt-cu12-libs, dllist, tensorrt_cu12, tensorrt, torch-tensorrt\n",
            "Successfully installed dllist-2.0.0 tensorrt-10.12.0.36 tensorrt-cu12-bindings-10.12.0.36 tensorrt-cu12-libs-10.12.0.36 tensorrt_cu12-10.12.0.36 torch-tensorrt-2.8.0\n",
            "Collecting nvidia-modelopt[all]\n",
            "  Downloading nvidia_modelopt-0.39.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting ninja (from nvidia-modelopt[all])\n",
            "  Downloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from nvidia-modelopt[all]) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from nvidia-modelopt[all]) (25.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.12/dist-packages (from nvidia-modelopt[all]) (2.11.10)\n",
            "Requirement already satisfied: nvidia-ml-py>=12 in /usr/local/lib/python3.12/dist-packages (from nvidia-modelopt[all]) (13.580.82)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from nvidia-modelopt[all]) (13.9.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from nvidia-modelopt[all]) (1.16.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nvidia-modelopt[all]) (4.67.1)\n",
            "Collecting pulp (from nvidia-modelopt[all])\n",
            "  Downloading pulp-3.3.0-py3-none-any.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from nvidia-modelopt[all]) (2024.11.6)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from nvidia-modelopt[all]) (0.6.2)\n",
            "Requirement already satisfied: torch>=2.6 in /usr/local/lib/python3.12/dist-packages (from nvidia-modelopt[all]) (2.8.0+cu126)\n",
            "Collecting torchprofile>=0.0.4 (from nvidia-modelopt[all])\n",
            "  Downloading torchprofile-0.0.4-py3-none-any.whl.metadata (303 bytes)\n",
            "Collecting cppimport (from nvidia-modelopt[all])\n",
            "  Downloading cppimport-22.8.2.tar.gz (26 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cupy-cuda12x in /usr/local/lib/python3.12/dist-packages (from nvidia-modelopt[all]) (13.6.0)\n",
            "Requirement already satisfied: ml_dtypes in /usr/local/lib/python3.12/dist-packages (from nvidia-modelopt[all]) (0.5.3)\n",
            "Collecting onnx-graphsurgeon (from nvidia-modelopt[all])\n",
            "  Downloading onnx_graphsurgeon-0.5.8-py2.py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting onnx~=1.19.0 (from nvidia-modelopt[all])\n",
            "  Downloading onnx-1.19.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (7.0 kB)\n",
            "Collecting onnxconverter-common~=1.16.0 (from nvidia-modelopt[all])\n",
            "  Downloading onnxconverter_common-1.16.0-py2.py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting onnxruntime-gpu~=1.22.0 (from nvidia-modelopt[all])\n",
            "  Downloading onnxruntime_gpu-1.22.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
            "Collecting onnxscript (from nvidia-modelopt[all])\n",
            "  Downloading onnxscript-0.5.6-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting polygraphy>=0.49.22 (from nvidia-modelopt[all])\n",
            "  Downloading polygraphy-0.49.26-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: accelerate>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from nvidia-modelopt[all]) (1.11.0)\n",
            "Requirement already satisfied: datasets>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from nvidia-modelopt[all]) (4.0.0)\n",
            "Requirement already satisfied: diffusers>=0.32.2 in /usr/local/lib/python3.12/dist-packages (from nvidia-modelopt[all]) (0.35.2)\n",
            "Requirement already satisfied: huggingface_hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from nvidia-modelopt[all]) (0.36.0)\n",
            "Requirement already satisfied: peft>=0.17.0 in /usr/local/lib/python3.12/dist-packages (from nvidia-modelopt[all]) (0.17.1)\n",
            "Requirement already satisfied: transformers<4.58,>=4.48 in /usr/local/lib/python3.12/dist-packages (from nvidia-modelopt[all]) (4.57.1)\n",
            "Collecting deepspeed>=0.9.6 (from nvidia-modelopt[all])\n",
            "  Downloading deepspeed-0.18.2.tar.gz (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate>=1.0.0->nvidia-modelopt[all]) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate>=1.0.0->nvidia-modelopt[all]) (6.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->nvidia-modelopt[all]) (3.20.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->nvidia-modelopt[all]) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->nvidia-modelopt[all]) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->nvidia-modelopt[all]) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->nvidia-modelopt[all]) (2.32.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->nvidia-modelopt[all]) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->nvidia-modelopt[all]) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->nvidia-modelopt[all]) (2025.3.0)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from deepspeed>=0.9.6->nvidia-modelopt[all]) (0.8.1)\n",
            "Collecting hjson (from deepspeed>=0.9.6->nvidia-modelopt[all])\n",
            "  Downloading hjson-3.1.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.12/dist-packages (from deepspeed>=0.9.6->nvidia-modelopt[all]) (1.1.2)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.12/dist-packages (from deepspeed>=0.9.6->nvidia-modelopt[all]) (9.0.0)\n",
            "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.12/dist-packages (from diffusers>=0.32.2->nvidia-modelopt[all]) (8.7.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from diffusers>=0.32.2->nvidia-modelopt[all]) (11.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.24.0->nvidia-modelopt[all]) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.24.0->nvidia-modelopt[all]) (1.2.0)\n",
            "Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.12/dist-packages (from onnx~=1.19.0->nvidia-modelopt[all]) (5.29.5)\n",
            "Collecting coloredlogs (from onnxruntime-gpu~=1.22.0->nvidia-modelopt[all])\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime-gpu~=1.22.0->nvidia-modelopt[all]) (25.9.23)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime-gpu~=1.22.0->nvidia-modelopt[all]) (1.13.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0->nvidia-modelopt[all]) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0->nvidia-modelopt[all]) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0->nvidia-modelopt[all]) (0.4.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->nvidia-modelopt[all]) (75.2.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->nvidia-modelopt[all]) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->nvidia-modelopt[all]) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->nvidia-modelopt[all]) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->nvidia-modelopt[all]) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->nvidia-modelopt[all]) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->nvidia-modelopt[all]) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->nvidia-modelopt[all]) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->nvidia-modelopt[all]) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->nvidia-modelopt[all]) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->nvidia-modelopt[all]) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->nvidia-modelopt[all]) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->nvidia-modelopt[all]) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->nvidia-modelopt[all]) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->nvidia-modelopt[all]) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->nvidia-modelopt[all]) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->nvidia-modelopt[all]) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->nvidia-modelopt[all]) (3.4.0)\n",
            "Requirement already satisfied: torchvision>=0.4 in /usr/local/lib/python3.12/dist-packages (from torchprofile>=0.0.4->nvidia-modelopt[all]) (0.23.0+cu126)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<4.58,>=4.48->nvidia-modelopt[all]) (0.22.1)\n",
            "Requirement already satisfied: mako in /usr/local/lib/python3.12/dist-packages (from cppimport->nvidia-modelopt[all]) (1.3.10)\n",
            "Collecting pybind11 (from cppimport->nvidia-modelopt[all])\n",
            "  Downloading pybind11-3.0.1-py3-none-any.whl.metadata (10.0 kB)\n",
            "Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.12/dist-packages (from cupy-cuda12x->nvidia-modelopt[all]) (0.8.3)\n",
            "Collecting onnx_ir<2,>=0.1.12 (from onnxscript->nvidia-modelopt[all])\n",
            "  Downloading onnx_ir-0.1.12-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->nvidia-modelopt[all]) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->nvidia-modelopt[all]) (2.19.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->nvidia-modelopt[all]) (3.13.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->nvidia-modelopt[all]) (0.1.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=3.0.0->nvidia-modelopt[all]) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=3.0.0->nvidia-modelopt[all]) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=3.0.0->nvidia-modelopt[all]) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=3.0.0->nvidia-modelopt[all]) (2025.10.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime-gpu~=1.22.0->nvidia-modelopt[all]) (1.3.0)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime-gpu~=1.22.0->nvidia-modelopt[all])\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib_metadata->diffusers>=0.32.2->nvidia-modelopt[all]) (3.23.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.6->nvidia-modelopt[all]) (3.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets>=3.0.0->nvidia-modelopt[all]) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets>=3.0.0->nvidia-modelopt[all]) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets>=3.0.0->nvidia-modelopt[all]) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->nvidia-modelopt[all]) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->nvidia-modelopt[all]) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->nvidia-modelopt[all]) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->nvidia-modelopt[all]) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->nvidia-modelopt[all]) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->nvidia-modelopt[all]) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->nvidia-modelopt[all]) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=3.0.0->nvidia-modelopt[all]) (1.17.0)\n",
            "Downloading onnx-1.19.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (18.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m129.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxconverter_common-1.16.0-py2.py3-none-any.whl (89 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.5/89.5 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime_gpu-1.22.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (283.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.2/283.2 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading polygraphy-0.49.26-py2.py3-none-any.whl (372 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m372.8/372.8 kB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchprofile-0.0.4-py3-none-any.whl (7.7 kB)\n",
            "Downloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (180 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.7/180.7 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_modelopt-0.39.0-py3-none-any.whl (864 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m865.0/865.0 kB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx_graphsurgeon-0.5.8-py2.py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.9/57.9 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxscript-0.5.6-py3-none-any.whl (683 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m683.0/683.0 kB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pulp-3.3.0-py3-none-any.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m102.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx_ir-0.1.12-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.3/129.3 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hjson-3.1.0-py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pybind11-3.0.1-py3-none-any.whl (293 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.6/293.6 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: deepspeed, cppimport\n",
            "  Building wheel for deepspeed (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for deepspeed: filename=deepspeed-0.18.2-py3-none-any.whl size=1763306 sha256=169066bb5ee150784c89edbd6419e30c35f6e82cbd21285ec46d93fa128407ee\n",
            "  Stored in directory: /root/.cache/pip/wheels/69/ad/2e/e03d4739ddc0417efd8a120c2b9e784005aa226037e558c163\n",
            "  Building wheel for cppimport (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cppimport: filename=cppimport-22.8.2-py3-none-any.whl size=17789 sha256=38459f333b1f187e0bce405468b48298fc9321adb512ec19a368be502a3a0041\n",
            "  Stored in directory: /root/.cache/pip/wheels/14/30/51/941b474cecac2b6d38a772e515f817b0619e0407ba786e1bd1\n",
            "Successfully built deepspeed cppimport\n",
            "Installing collected packages: hjson, pybind11, pulp, polygraphy, ninja, humanfriendly, onnx, cppimport, coloredlogs, onnxruntime-gpu, onnxconverter-common, onnx_ir, onnx-graphsurgeon, onnxscript, deepspeed, torchprofile, nvidia-modelopt\n",
            "Successfully installed coloredlogs-15.0.1 cppimport-22.8.2 deepspeed-0.18.2 hjson-3.1.0 humanfriendly-10.0 ninja-1.13.0 nvidia-modelopt-0.39.0 onnx-1.19.1 onnx-graphsurgeon-0.5.8 onnx_ir-0.1.12 onnxconverter-common-1.16.0 onnxruntime-gpu-1.22.0 onnxscript-0.5.6 polygraphy-0.49.26 pulp-3.3.0 pybind11-3.0.1 torchprofile-0.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Датасет"
      ],
      "metadata": {
        "id": "xFFx7LYUG6Qo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch_tensorrt\n",
        "import modelopt.torch.quantization as mtq\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "testing_dataset = torchvision.datasets.CIFAR10(\n",
        "    root=\"./data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transforms.Compose(\n",
        "        [\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "        ]\n",
        "    ),\n",
        ")\n",
        "\n",
        "testing_dataloader = torch.utils.data.DataLoader(\n",
        "    testing_dataset, batch_size=1, shuffle=False, num_workers=1\n",
        ")\n"
      ],
      "metadata": {
        "id": "oOW61jT5KKix"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Функция калибровки"
      ],
      "metadata": {
        "id": "gQg7Q5QA1p_A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_loop(model):\n",
        "    for img, _ in testing_dataloader:\n",
        "        img = img.to(device)\n",
        "        model(img)\n",
        "\n"
      ],
      "metadata": {
        "id": "YbwkIeziKqDT"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Модель"
      ],
      "metadata": {
        "id": "U_EX4cdH12dC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = torchvision.models.resnet18().to(device)"
      ],
      "metadata": {
        "id": "t7upjKOB13ti"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8tvEPHSx3TTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Квантизация при помощи TensorRT Model Optimiser"
      ],
      "metadata": {
        "id": "y3kBiS_K1yFY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from functools import partial\n",
        "\n",
        "config = mtq.INT8_DEFAULT_CFG\n",
        "\n",
        "quantized_model = mtq.quantize(model, config, forward_loop)"
      ],
      "metadata": {
        "id": "s8TAxxJDKrXC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75ab2cfa-d9d5-45b6-cfaa-fdeb8b30318d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inserted 107 quantizers\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mtq.print_quant_summary(quantized_model)"
      ],
      "metadata": {
        "id": "qF0Nl9Cc4IM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Задание на семинар\n",
        "\n",
        "Нужно квантизировать при помощи TensorRT любую модель из torchvision или timm (hugging-face) до int8 и до float16. Затем нужно проверить скорость работы получившихся вариаций модели (float32 - исходная, float16 и int8) и их размер. Результаты привести в блокноте."
      ],
      "metadata": {
        "id": "3FCzs4kJG6pH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm torchao"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXOByuLRq8sY",
        "outputId": "f201aefe-3505-48bc-f7d4-902822b85a22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: timm in /usr/local/lib/python3.12/dist-packages (1.0.21)\n",
            "Requirement already satisfied: torchao in /usr/local/lib/python3.12/dist-packages (0.10.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from timm) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from timm) (0.23.0+cu126)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from timm) (6.0.3)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (from timm) (0.36.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from timm) (0.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (25.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (1.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->timm) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->timm) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision->timm) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision->timm) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->timm) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->timm) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (2025.10.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Tuple\n",
        "from torchao.utils import (\n",
        "    benchmark_model,\n",
        "    unwrap_tensor_subclass,\n",
        ")\n",
        "from torch import nn\n",
        "import torch\n",
        "\n",
        "import os\n",
        "\n",
        "def benchmark_speed(model_orig: nn.Module,\n",
        "                    model_quant: nn.Module,\n",
        "                    example_inputs: torch.Tensor,\n",
        "                    num_runs: int = 100):\n",
        "    torch._dynamo.reset()\n",
        "    orig_time = benchmark_model(model_orig, num_runs, example_inputs)\n",
        "    quant_time = benchmark_model(model_quant, num_runs, example_inputs)\n",
        "\n",
        "    print(\"orig mean time: %0.3f ms\" % orig_time)\n",
        "    print(\"quant mean time: %0.3f ms\" % quant_time)\n",
        "    print(\"speedup: %0.1fx\" % (orig_time / quant_time))\n",
        "    torch._dynamo.reset()\n",
        "\n",
        "\n",
        "def benchmark_size(model_orig: nn.Module, model_quant: nn.Module):\n",
        "    torch.save(model_orig, \"/tmp/orig_model.pt\")\n",
        "    torch.save(model_quant, \"/tmp/quant_model.pt\")\n",
        "    quant_model_size_mb = os.path.getsize(\"/tmp/quant_model.pt\") / 1024 / 1024\n",
        "    orig_model_size_mb = os.path.getsize(\"/tmp/orig_model.pt\") / 1024 / 1024\n",
        "\n",
        "    print(\"quant model size: %.2f MB\" % quant_model_size_mb)\n",
        "\n",
        "    print(\"original model size: %.2f MB\" % orig_model_size_mb)\n"
      ],
      "metadata": {
        "id": "zchnak2Pq_hH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import timm\n",
        "\n",
        "model = timm.create_model('vit_base_patch14_dinov2.lvd142m').cuda()\n",
        "model\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4WUsTPwr33l",
        "outputId": "594cb979-1d8f-4cc9-8ba1-5a1dcbc82209"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VisionTransformer(\n",
              "  (patch_embed): PatchEmbed(\n",
              "    (proj): Conv2d(3, 768, kernel_size=(14, 14), stride=(14, 14))\n",
              "    (norm): Identity()\n",
              "  )\n",
              "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
              "  (patch_drop): Identity()\n",
              "  (norm_pre): Identity()\n",
              "  (blocks): Sequential(\n",
              "    (0): Block(\n",
              "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "        (q_norm): Identity()\n",
              "        (k_norm): Identity()\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls1): LayerScale()\n",
              "      (drop_path1): Identity()\n",
              "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls2): LayerScale()\n",
              "      (drop_path2): Identity()\n",
              "    )\n",
              "    (1): Block(\n",
              "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "        (q_norm): Identity()\n",
              "        (k_norm): Identity()\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls1): LayerScale()\n",
              "      (drop_path1): Identity()\n",
              "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls2): LayerScale()\n",
              "      (drop_path2): Identity()\n",
              "    )\n",
              "    (2): Block(\n",
              "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "        (q_norm): Identity()\n",
              "        (k_norm): Identity()\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls1): LayerScale()\n",
              "      (drop_path1): Identity()\n",
              "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls2): LayerScale()\n",
              "      (drop_path2): Identity()\n",
              "    )\n",
              "    (3): Block(\n",
              "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "        (q_norm): Identity()\n",
              "        (k_norm): Identity()\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls1): LayerScale()\n",
              "      (drop_path1): Identity()\n",
              "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls2): LayerScale()\n",
              "      (drop_path2): Identity()\n",
              "    )\n",
              "    (4): Block(\n",
              "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "        (q_norm): Identity()\n",
              "        (k_norm): Identity()\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls1): LayerScale()\n",
              "      (drop_path1): Identity()\n",
              "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls2): LayerScale()\n",
              "      (drop_path2): Identity()\n",
              "    )\n",
              "    (5): Block(\n",
              "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "        (q_norm): Identity()\n",
              "        (k_norm): Identity()\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls1): LayerScale()\n",
              "      (drop_path1): Identity()\n",
              "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls2): LayerScale()\n",
              "      (drop_path2): Identity()\n",
              "    )\n",
              "    (6): Block(\n",
              "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "        (q_norm): Identity()\n",
              "        (k_norm): Identity()\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls1): LayerScale()\n",
              "      (drop_path1): Identity()\n",
              "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls2): LayerScale()\n",
              "      (drop_path2): Identity()\n",
              "    )\n",
              "    (7): Block(\n",
              "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "        (q_norm): Identity()\n",
              "        (k_norm): Identity()\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls1): LayerScale()\n",
              "      (drop_path1): Identity()\n",
              "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls2): LayerScale()\n",
              "      (drop_path2): Identity()\n",
              "    )\n",
              "    (8): Block(\n",
              "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "        (q_norm): Identity()\n",
              "        (k_norm): Identity()\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls1): LayerScale()\n",
              "      (drop_path1): Identity()\n",
              "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls2): LayerScale()\n",
              "      (drop_path2): Identity()\n",
              "    )\n",
              "    (9): Block(\n",
              "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "        (q_norm): Identity()\n",
              "        (k_norm): Identity()\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls1): LayerScale()\n",
              "      (drop_path1): Identity()\n",
              "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls2): LayerScale()\n",
              "      (drop_path2): Identity()\n",
              "    )\n",
              "    (10): Block(\n",
              "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "        (q_norm): Identity()\n",
              "        (k_norm): Identity()\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls1): LayerScale()\n",
              "      (drop_path1): Identity()\n",
              "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls2): LayerScale()\n",
              "      (drop_path2): Identity()\n",
              "    )\n",
              "    (11): Block(\n",
              "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "        (q_norm): Identity()\n",
              "        (k_norm): Identity()\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls1): LayerScale()\n",
              "      (drop_path1): Identity()\n",
              "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls2): LayerScale()\n",
              "      (drop_path2): Identity()\n",
              "    )\n",
              "  )\n",
              "  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "  (fc_norm): Identity()\n",
              "  (head_drop): Dropout(p=0.0, inplace=False)\n",
              "  (head): Identity()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "from torchvision import transforms\n",
        "\n",
        "testing_dataset = torchvision.datasets.CIFAR10(\n",
        "    root=\"./data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transforms.Compose(\n",
        "        [\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "            transforms.Resize((518, 518))\n",
        "        ]\n",
        "    ),\n",
        ")\n",
        "\n",
        "testing_dataloader = torch.utils.data.DataLoader(\n",
        "    testing_dataset, batch_size=1, shuffle=False, num_workers=1\n",
        ")"
      ],
      "metadata": {
        "id": "3ngduY-G2o4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_tensorrt.ts.ptq import DataLoaderCalibrator, CalibrationAlgo\n",
        "\n",
        "calibrator = DataLoaderCalibrator(\n",
        "    testing_dataloader,\n",
        "    cache_file=\"./calibration.cache\",\n",
        "    use_cache=False,\n",
        "    algo_type=CalibrationAlgo.ENTROPY_CALIBRATION_2,\n",
        "    device=torch.device(\"cuda:0\"),\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEA_HYmk3Dcs",
        "outputId": "2820579f-4109-4e54-acae-dac5350f4b9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:py.warnings:/tmp/ipython-input-3108842424.py:3: DeprecationWarning: Int8 PTQ Calibrator has been deprecated by TensorRT, please plan on porting to a NVIDIA Model Optimizer Toolkit based workflow. See: https://pytorch.org/TensorRT/tutorials/_rendered_examples/dynamo/vgg16_ptq.html for more details\n",
            "  calibrator = DataLoaderCalibrator(\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "quantized_model = torch_tensorrt.compile(model, inputs=[torch_tensorrt.Input((1, 3, 518, 518))],\n",
        "                                    enabled_precisions={torch.float, torch.half, torch.int8},\n",
        "                                    # calibrator=calibrator,\n",
        "                                    device='cuda:0')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "7TdHXM3J3ECF",
        "outputId": "f3f92da2-5e62-4a31-d644-37b4bbd4e85b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Given dtype that does not have direct mapping to torch (dtype.unknown), defaulting to torch.float\n",
            "WARNING:torch_tensorrt [TensorRT Conversion Context]:Calibrator is not being used. Users must provide dynamic range for all tensors that are not Int32 or Bool.\n",
            "ERROR:torch_tensorrt [TensorRT Conversion Context]:IBuilder::buildSerializedNetwork: Error Code 4: Internal Error (Calibration failure occurred with no scaling factors detected. This could be due to no int8 calibrator or insufficient custom scales for network layers. Please see int8 sample to setup calibration correctly.)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3308288802.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m quantized_model = torch_tensorrt.compile(model, inputs=[torch_tensorrt.Input((1, 3, 518, 518))],\n\u001b[0m\u001b[1;32m      2\u001b[0m                                     \u001b[0menabled_precisions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhalf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint8\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                     \u001b[0;31m# calibrator=calibrator,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                     device='cuda:0')\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch_tensorrt/_compile.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(module, ir, inputs, arg_inputs, kwarg_inputs, enabled_precisions, **kwargs)\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorchtrt_arg_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwarg_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorchtrt_kwarg_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         )\n\u001b[0;32m--> 289\u001b[0;31m         trt_graph_module = dynamo_compile(\n\u001b[0m\u001b[1;32m    290\u001b[0m             \u001b[0mexp_program\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0marg_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorchtrt_arg_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch_tensorrt/dynamo/_compiler.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(exported_program, inputs, arg_inputs, kwarg_inputs, device, disable_tf32, assume_dynamic_shape_support, sparse_weights, enabled_precisions, engine_capability, num_avg_timing_iters, workspace_size, dla_sram_size, dla_local_dram_size, dla_global_dram_size, truncate_double, require_full_compilation, min_block_size, torch_executed_ops, torch_executed_modules, pass_through_build_failures, max_aux_streams, version_compatible, optimization_level, use_python_runtime, use_fast_partitioner, enable_experimental_decompositions, dryrun, hardware_compatible, timing_cache_path, lazy_engine_init, cache_built_engines, reuse_cached_engines, engine_cache_dir, engine_cache_size, custom_engine_cache, use_explicit_typing, use_fp32_acc, refit_identical_engine_weights, strip_engine_weights, immutable_weights, enable_weight_streaming, tiling_optimization_level, l2_limit_for_tiling, offload_module_to_cpu, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0;34m\"Remaining GPU memory may not be enough to compile the TensorRT engine for this model resulting in an OOM error, Consider setting offload_module_to_cpu=True\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m             )\n\u001b[0;32m--> 722\u001b[0;31m     trt_gm = compile_module(\n\u001b[0m\u001b[1;32m    723\u001b[0m         \u001b[0mgm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrt_arg_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrt_kwarg_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msettings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine_cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch_tensorrt/dynamo/_compiler.py\u001b[0m in \u001b[0;36mcompile_module\u001b[0;34m(gm, sample_arg_inputs, sample_kwarg_inputs, settings, engine_cache, _debugger_config)\u001b[0m\n\u001b[1;32m    950\u001b[0m         \u001b[0;31m# Create TRT engines from submodule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdryrun\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             trt_module = convert_module(\n\u001b[0m\u001b[1;32m    953\u001b[0m                 \u001b[0msubmodule\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m                 \u001b[0msubmodule_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch_tensorrt/dynamo/conversion/_conversion.py\u001b[0m in \u001b[0;36mconvert_module\u001b[0;34m(module, inputs, settings, name, engine_cache)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mPythonTorchTensorRTModule\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mTorchTensorRTModule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \"\"\"\n\u001b[0;32m---> 88\u001b[0;31m     interpreter_result = interpret_module_to_result(\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msettings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine_cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch_tensorrt/dynamo/conversion/_conversion.py\u001b[0m in \u001b[0;36minterpret_module_to_result\u001b[0;34m(module, inputs, settings, arg_inputs, kwarg_inputs, engine_cache)\u001b[0m\n\u001b[1;32m     65\u001b[0m     )\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0minterpreter_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minterpreter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minterpreter_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch_tensorrt/dynamo/conversion/_TRTInterpreter.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, strict_type_constraints, algorithm_selector, tactic_sources)\u001b[0m\n\u001b[1;32m    740\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuilder_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m         )\n\u001b[0;32m--> 742\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mserialized_engine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m         _LOGGER.info(\n",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MFpIPCB8_LLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# benchmark_speed(model, quantized_model, torch.rand(1, 3, 518, 518).cuda())\n",
        "benchmark_size(model, quantized_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_NJ2cMc4Ghs",
        "outputId": "10e80a64-d77c-44aa-fd9d-17ed554375e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "quant model size: 937.36 MB\n",
            "original model size: 330.39 MB\n"
          ]
        }
      ]
    }
  ]
}